{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Lab_6_1_solutions.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"JC0HyZ2pZiQM"},"source":["# Week 6 (Part 1): Dictionary Methods for WSD\n","\n","We have seen that many words have many different senses.  In order to make the correct decision about the meaning of a sentence or a document, an application often needs to be able to **disambiguate** individual words, that is, choose the correct sense given the context.\n","\n","In this lab we will be looking at methods for word sense disambiguation (WSD) that make use of dictionaries or other lexical resources (also referred to as **knowledge-based methods** for WSD).  In particular, we will look at\n","* simplified Lesk\n","* adapted Lesk\n","* minimising distance in a semantic hierarchy\n","\n","As in the previous lab, we will be using WordNet as our lexical resource.  So, first, lets import it."]},{"cell_type":"code","metadata":{"id":"41GBsTFxZiQN","executionInfo":{"status":"ok","timestamp":1604676283114,"user_tz":0,"elapsed":49878,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"562906ea-78bd-42f2-db5a-d869890a9286","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('wordnet_ic')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","from nltk.corpus import wordnet as wn\n","from nltk.corpus import wordnet_ic as wn_ic\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import sys\n","import operator\n","\n","#make sure that the path to your utils.py file is correct for your computer\n","sys.path.append('/content/drive/My Drive/NLE Notebooks/Week4LabsSolutions/')\n","from utils import *\n","from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Sussex NLTK root directory is /content/drive/My Drive/NLE Notebooks/resources\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VuvL-ZcKZiQv"},"source":["## Simplified Lesk\n","\n","The Lesk algorithm is based on the intuition that the correct combination of senses in a sentence will share more common words in their definitions.\n","\n","It is computationally very expensive to compare all possible sense combinations of words in a sentence.  If each word has just 2 senses, then there are $2^n$ possible sense combinations.\n","\n","In the simplifed Lesk algorithm, below, we consider each word in turn and choose the sense whose definition has more **overlap** with the contextual words in the sentence.\n"]},{"cell_type":"code","metadata":{"id":"mvya6K_yZiQw","executionInfo":{"status":"ok","timestamp":1604676378433,"user_tz":0,"elapsed":1256,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}}},"source":["\n","def simplifiedLesk(word,sentence):\n","    '''\n","    Use the simplified Lesk algorithm to disambiguate word in the context of sentence\n","    word: a String which is the word to be disambiguated\n","    sentence: a String which is the sentence containing the word\n","    :return: a pair (chosen sense definition, overlap score)\n","    '''\n","    \n","    #construct the set of context word tokens for the sentence: all words in sentence - word itself\n","    contexttokens=set(word_tokenize(sentence))-{word}\n","    \n","    #get all the possible synsets for the word\n","    synsets=wn.synsets(word)\n","    scores=[]\n","    \n","    #iterate over synsets\n","    for synset in synsets:\n","        #get the set of tokens in the definition of the synset\n","        sensetokens=set(word_tokenize(synset.definition()))\n","        #find the size of the intersection of the sensetokens set with the contexttokens set\n","        scores.append((synset.definition(),len(sensetokens.intersection(contexttokens))))\n","    \n","    #sort the score list in descending order by the score (which is item with index 1 in the pair)\n","    sortedscores=sorted(scores,key=operator.itemgetter(1),reverse=True) \n","    #print(sortedscores)\n","    return sortedscores[0]\n","    \n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tr9VX9byZiQ2"},"source":["Now lets test it on a couple of sentences containing the word *bank*"]},{"cell_type":"code","metadata":{"id":"NBipSmeoZiQ3","executionInfo":{"status":"ok","timestamp":1604676384448,"user_tz":0,"elapsed":2563,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"6c8aaebd-a216-47a7-a92b-0a6b7dd7a331","colab":{"base_uri":"https://localhost:8080/"}},"source":["banksentences=[\"he borrowed money from the bank\",\"he sat on the bank of the river and watched the currents\"]\n","for sentence in banksentences:\n","    print(sentence,\":\",simplifiedLesk(\"bank\",sentence))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["he borrowed money from the bank : ('a financial institution that accepts deposits and channels the money into lending activities', 2)\n","he sat on the bank of the river and watched the currents : ('sloping land (especially the slope beside a body of water)', 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LU3hQBsIZiRA"},"source":["It actually appears not to do too bad.  However, this is more by luck than anything else.   If you inspect the sentences and the definitions, you will notice that most of the overlap is currently generated by stopwords.\n","\n","### Exercise 1.1\n","Improve the SimplifiedLesk algorithm by carrying out:\n","* case and number normalisation \n","* stopword filtering\n","* lemmatisation\n","\n","You should find some useful functions for doing this in `utils.py` based on earlier labs.\n","\n","Make sure you test it.  Unfortunately, whilst the first sentence is still disambiguated correctly (with an overlap of 1), you should now find 0 overlap between any of the senses and the second sentence."]},{"cell_type":"code","metadata":{"id":"whDd-DowZiRB","executionInfo":{"status":"ok","timestamp":1604676549320,"user_tz":0,"elapsed":988,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}}},"source":["\n","def simplifiedLesk(word,sentence):\n","    '''\n","    Use the simplified Lesk algorithm to disambiguate word in the context of sentence\n","    word: a String which is the word to be disambiguated\n","    sentence: a String which is the sentence containing the word\n","    :return: a pair (chosen sense definition, overlap score)\n","    '''\n","    \n","    #construct the set of context word tokens for the sentence: all words in sentence - word itself\n","    lemma =WordNetLemmatizer()\n","    contexttokens=set((filter_stopwords(normalise(word_tokenize(sentence)))))-{word}\n","    contextlemmas={lemma.lemmatize(contexttoken) for contexttoken in contexttokens}\n","    \n","    #get all the possible synsets for the word\n","    synsets=wn.synsets(word)\n","    scores=[]\n","    \n","    #iterate over synsets\n","    for synset in synsets:\n","        #get the set of tokens in the definition of the synset\n","        sensetokens=set(filter_stopwords(normalise(word_tokenize(synset.definition()))))\n","        senselemmas={lemma.lemmatize(token) for token in sensetokens}\n","        #find the size of the intersection of the sensetokens set with the contexttokens set\n","        scores.append((synset.definition(),len(senselemmas.intersection(contextlemmas))))\n","    \n","    #sort the score list in descending order by the score (which is item with index 1 in the pair)\n","    sortedscores=sorted(scores,key=operator.itemgetter(1),reverse=True) \n","    #print(sortedscores)\n","    return sortedscores[0]\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7ML51PzZiRI","executionInfo":{"status":"ok","timestamp":1604676552397,"user_tz":0,"elapsed":927,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"ede12005-d157-4bf2-96b6-0d39c0228f71","colab":{"base_uri":"https://localhost:8080/"}},"source":["for sentence in banksentences:\n","    print(sentence,\":\",simplifiedLesk(\"bank\",sentence))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["he borrowed money from the bank : ('a financial institution that accepts deposits and channels the money into lending activities', 1)\n","he sat on the bank of the river and watched the currents : ('sloping land (especially the slope beside a body of water)', 0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zy9p2xphZiRO"},"source":["## Adapted Lesk\n","WordNet definitions are very short.  However, it is possible to create a bigger set of sense words by including information about the hypernyms and hyponyms of each sense.\n","\n","### Exercise 2.1\n","Adapt the Lesk algorithm to include in `sensetokens`:\n","* all of the lemma_names for the sense itself\n","* all of the lemma_names for the hypernyms of the sense\n","* all of the lemma_names for the hypoynyms of the sense\n","* all of the words from the definitions of the hypernyms of the sense\n","* all of the words from the definitions of the hyponyms of the sense\n","\n","Make sure you carry out normalisation and lemmatisation of these words as before\n","\n","Test each adaptation you make on the bank sentences, recording the overlap observed with the chosen sense."]},{"cell_type":"code","metadata":{"id":"YUfDx_WIZiRO","executionInfo":{"status":"ok","timestamp":1604676719267,"user_tz":0,"elapsed":942,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}}},"source":["def adaptedLesk(word,sentence):\n","    '''\n","    Use the simplified Lesk algorithm to disambiguate word in the context of sentence, using standard WordNet adaptations\n","    word: a String which is the word to be disambiguated\n","    sentence: a String which is the sentence containing the word\n","    :return: a pair (chosen sense definition, overlap score)\n","    '''\n","    \n","    #construct the set of context word tokens for the sentence: all words in sentence - word itself\n","    \n","    lemma =WordNetLemmatizer()\n","    contexttokens=set((filter_stopwords(normalise(word_tokenize(sentence)))))-{word}\n","    contextlemmas={lemma.lemmatize(contexttoken) for contexttoken in contexttokens}\n","    #get all the possible synsets for the word\n","    synsets=wn.synsets(word)\n","    scores=[]\n","    \n","    #iterate over synsets\n","    for synset in synsets:\n","        #get the set of tokens in the definition of the synset\n","        sensetokens=word_tokenize(synset.definition())\n","        sensetokens+=synset.lemma_names()\n","        for hypernym in synset.hypernyms():\n","            sensetokens+=hypernym.lemma_names()\n","            sensetokens+=word_tokenize(hypernym.definition())\n","        for hyponym in synset.hyponyms():\n","            sensetokens+=hyponym.lemma_names()\n","            sensetokens+=word_tokenize(hyponym.definition())\n","        \n","        sensetokens=set(filter_stopwords(normalise(sensetokens)))\n","        senselemmas={lemma.lemmatize(token) for token in sensetokens}\n","        #find the size of the intersection of the sensetokens set with the contexttokens set\n","        scores.append((synset.definition(),len(senselemmas.intersection(contextlemmas))))\n","    \n","    #sort the score list in descending order by the score (which is item with index 1 in the pair)\n","    sortedscores=sorted(scores,key=operator.itemgetter(1),reverse=True) \n","    #print(sortedscores)\n","    return sortedscores[0]\n","    "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ne2Vj-dzZiRR","executionInfo":{"status":"ok","timestamp":1604676723313,"user_tz":0,"elapsed":1197,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"c9b8cd98-f9fd-4066-b43e-459fd1bb067b","colab":{"base_uri":"https://localhost:8080/"}},"source":["for sentence in banksentences:\n","    print(sentence,\":\",adaptedLesk(\"bank\",sentence))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["he borrowed money from the bank : ('a financial institution that accepts deposits and channels the money into lending activities', 1)\n","he sat on the bank of the river and watched the currents : ('sloping land (especially the slope beside a body of water)', 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A3CA45SKZiRV"},"source":["### Exercise 2.2\n","From a sample of 1000 sentences from the dvd category of the Amazon review corpus (use the `sample_raw_sents()` method), find sentences which contain the stem or lemma *film*.  Use your AdaptedLesk algoritm to disambiguate them.  You may want to adapt it slightly so that it takes as input a list or a set of context tokens or stems rather than the sentence itself.  Record the number of instances of each sense of *film* predicted by this algorithm."]},{"cell_type":"code","metadata":{"id":"zAiwv0dIZiRi","executionInfo":{"status":"ok","timestamp":1604676820584,"user_tz":0,"elapsed":884,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"19e8d58c-80cb-4d2c-e78e-508dee6b6483","colab":{"base_uri":"https://localhost:8080/"}},"source":["filmsynsets=wn.synsets(\"film\")\n","for s in filmsynsets:\n","    print(s.definition())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["a form of entertainment that enacts a story by sound and a sequence of images giving the illusion of continuous movement\n","a medium that disseminates moving pictures\n","photographic material consisting of a base of celluloid covered with a photographic emulsion; used to make negatives or transparencies\n","a thin coating or layer\n","a thin sheet of (usually plastic and usually transparent) material used to wrap or cover things\n","make a film or photograph of something\n","record in film\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HJ8VunzvZiRW","executionInfo":{"status":"ok","timestamp":1604676886854,"user_tz":0,"elapsed":56901,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}}},"source":["dvd_reader = AmazonReviewCorpusReader().category(\"dvd\")\n","sentences=dvd_reader.sample_raw_sents(1000)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_Sox0RMZiRb","executionInfo":{"status":"ok","timestamp":1604676961408,"user_tz":0,"elapsed":961,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"04e75c8f-3264-4cd1-b20b-266c9be31dc6","colab":{"base_uri":"https://localhost:8080/"}},"source":["def lemmatize(alist):\n","    lemma=WordNetLemmatizer()\n","    return [lemma.lemmatize(token) for token in alist]\n","tokenisedsentences=[lemmatize(normalise(word_tokenize(sentence))) for sentence in sentences]\n","filmsentences=[sentence for sentence in tokenisedsentences if \"film\" in sentence]\n","print(len(sentences),len(filmsentences))\n","print(filmsentences[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1000 99\n","['but', 'the', 'film', 'is', 'nevertheless', 'inspirational', ',', 'and', 'one', 'that', 'my', 'family', 'thoroughly', 'enjoyed', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_bCFNdywZiRf","executionInfo":{"status":"ok","timestamp":1604677070951,"user_tz":0,"elapsed":3500,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"d0163326-744a-4e40-9416-1e8057af7d08","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","def adaptedLesk(word,contexttokens):\n","    '''\n","    Use the simplified Lesk algorithm to disambiguate word in the context of sentence, using standard WordNet adaptations\n","    word: a String which is the word to be disambiguated\n","    contexttokens: a list of context tokens which have been normalised, stemmed and stopword filtered\n","    :return: a pair (chosen sense definition, overlap score)\n","    '''\n","    \n","    #construct the set of context word tokens for the sentence: all words in sentence - word itself\n","    lemma =WordNetLemmatizer()\n","    contexttokens=set(contexttokens)-{lemma.lemmatize(word)}\n","    \n","    #get all the possible synsets for the word\n","    synsets=wn.synsets(word)\n","    scores=[]\n","    \n","    #iterate over synsets\n","    for synset in synsets:\n","        #get the set of tokens in the definition of the synset\n","        sensetokens=word_tokenize(synset.definition())\n","        sensetokens+=synset.lemma_names()\n","        for hypernym in synset.hypernyms():\n","            sensetokens+=hypernym.lemma_names()\n","            sensetokens+=word_tokenize(hypernym.definition())\n","        for hyponym in synset.hyponyms():\n","            sensetokens+=hyponym.lemma_names()\n","            sensetokens+=word_tokenize(hyponym.definition())\n","        \n","        sensetokens=set(lemmatize(filter_stopwords(normalise(sensetokens))))\n","        #find the size of the intersection of the sensetokens set with the contexttokens set\n","        scores.append((synset.definition(),len(sensetokens.intersection(contexttokens))))\n","    \n","    #sort the score list in descending order by the score (which is item with index 1 in the pair)\n","    sortedscores=sorted(scores,key=operator.itemgetter(1),reverse=True) \n","    #print(sortedscores)\n","    return sortedscores[0]\n","\n","results={}\n","for sentence in filmsentences:\n","    res=adaptedLesk(\"film\",sentence)\n","    results[res[0]]=results.get(res[0],0)+1\n","\n","print(results)\n","    "],"execution_count":12,"outputs":[{"output_type":"stream","text":["{'a form of entertainment that enacts a story by sound and a sequence of images giving the illusion of continuous movement': 88, 'photographic material consisting of a base of celluloid covered with a photographic emulsion; used to make negatives or transparencies': 9, 'a thin sheet of (usually plastic and usually transparent) material used to wrap or cover things': 2}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pcb2BEEjZiRl"},"source":["### Exercise 2.3\n","Inspect some of the individual predictions for your film sentences (at least one for each sense predicted).  Do you agree with the sense prediction?"]},{"cell_type":"code","metadata":{"id":"qClidLW1ZiRm","executionInfo":{"status":"ok","timestamp":1604677131178,"user_tz":0,"elapsed":924,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"113007ca-755f-421c-fb84-256bfbd3879f","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(filmsentences[0])\n","adaptedLesk(\"film\",filmsentences[0])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['but', 'the', 'film', 'is', 'nevertheless', 'inspirational', ',', 'and', 'one', 'that', 'my', 'family', 'thoroughly', 'enjoyed', '.']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('a form of entertainment that enacts a story by sound and a sequence of images giving the illusion of continuous movement',\n"," 0)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"z1X7B5hPeoRU","executionInfo":{"status":"ok","timestamp":1604677181642,"user_tz":0,"elapsed":2836,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"727a52db-5c96-4182-daea-39ed4074b203","colab":{"base_uri":"https://localhost:8080/"}},"source":["results={}\n","for sentence in filmsentences:\n","  res=adaptedLesk(\"film\",sentence)\n","  if res[0] not in results.keys():\n","    print(sentence)\n","    print(res)\n","  results[res[0]]=results.get(res[0],0)+1\n","\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["['but', 'the', 'film', 'is', 'nevertheless', 'inspirational', ',', 'and', 'one', 'that', 'my', 'family', 'thoroughly', 'enjoyed', '.']\n","('a form of entertainment that enacts a story by sound and a sequence of images giving the illusion of continuous movement', 0)\n","['tim', 'burton', \"'s\", 'film', 'coupled', 'with', 'depp', \"'s\", 'remarkable', 'acting', 'ability', 'make', 'this', 'movie', 'a', 'classic', '.']\n","('photographic material consisting of a base of celluloid covered with a photographic emulsion; used to make negatives or transparencies', 2)\n","['there', 'wa', 'a', 'few', 'thing', 'that', 'went', 'wrong', 'with', 'pi', 'that', 'i', 'wont', 'go', 'into', ',', 'but', 'a', 'with', 'most', 'filmmaker', 'making', 'no', 'budget', 'film', 'all', 'their', 'mistake', 'suddenly', 'become', 'artistic', 'expression', '.']\n","('a thin sheet of (usually plastic and usually transparent) material used to wrap or cover things', 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xr9Y5eC8ZiRs"},"source":["## Minimising the Distance in the Semantic Hierarchy (**EXTENSION**)\n","This WSD method is based on the intuition that the concepts mentioned in a sentence will be close together in the hyponym hierarchy.\n","\n","### Exercise 3.1 (**EXTENSION**)\n","Write a function `max_sim(word, contextlemmas,pos)`which will choose the sense of a *word* given its context *sentence* using a WordNet based semantic similarity measure (see Lab_5_1).  You can assume that the part of speech of the word is known and is supplied to the function as another argument.\n","\n","For each **sense** of the word under consideration:\n","* compute its semantic similarity with each context **lemma** of the same part of speech \n","* sum the semantic similarities over the sentence\n","\n","Choose the **sense** with the maximum sum.\n","\n","Test your function on the bank sentences.  You should find, disappointingly for the method,  that the first sentence has a maximum score of 2.71 with \"an arrangement of similar objects in a row or in tiers\" and the second sentence has a maximum socre of 4.68 with \"an arrangement of similar objects in a row or in tiers\"."]},{"cell_type":"code","metadata":{"id":"bJv22tR5ZiRs","executionInfo":{"status":"ok","timestamp":1604677499802,"user_tz":0,"elapsed":1530,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"b02019fe-0415-4627-ffce-170a56b88de1","colab":{"base_uri":"https://localhost:8080/"}},"source":["def max_sim(word,contextlemmas,pos=wn.NOUN):\n","    \n","    synsets=wn.synsets(word,pos)\n","    scores=[]\n","    for synset in synsets:\n","        total=0\n","        for lemma in contextlemmas:\n","            sofar=0\n","            for synsetB in wn.synsets(lemma,pos):\n","                sim=wn.path_similarity(synset,synsetB)\n","                if sim>sofar:\n","                    sofar=sim\n","            total+=sofar\n","        scores.append((synset.definition(),total))\n","    sortedscores=sorted(scores,key=operator.itemgetter(1),reverse=True) \n","    #print(sortedscores)\n","    return sortedscores[0]\n","\n","\n","for sentence in banksentences:\n","    print(sentence,\":\",max_sim(\"bank\",sentence,wn.NOUN))    "],"execution_count":15,"outputs":[{"output_type":"stream","text":["he borrowed money from the bank : ('an arrangement of similar objects in a row or in tiers', 2.7126262626262627)\n","he sat on the bank of the river and watched the currents : ('an arrangement of similar objects in a row or in tiers', 4.683333333333332)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NsS3MRkJZiRw"},"source":["### Exercise 3.2 (**EXTENSION**)\n","* Run your max_sim function on all of your film sentences and record the number of predictions for each sense.\n","* Inspect some of the individual predictions.\n","* Compare the results with those from the AdaptedLesk algorithm and draw some conclusions."]},{"cell_type":"code","metadata":{"id":"TuWRucaIZiRx","executionInfo":{"status":"ok","timestamp":1604677536570,"user_tz":0,"elapsed":4473,"user":{"displayName":"Julie Weeds","photoUrl":"","userId":"13844540934373660130"}},"outputId":"978c0b30-9a11-4c4d-b781-23cf348acf3a","colab":{"base_uri":"https://localhost:8080/"}},"source":["results={}\n","for sentence in filmsentences:\n","    res=max_sim(\"film\",sentence, wn.NOUN)\n","    results[res[0]]=results.get(res[0],0)+1\n","\n","print(results)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["{'a thin coating or layer': 70, 'a form of entertainment that enacts a story by sound and a sequence of images giving the illusion of continuous movement': 29}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mvDtHvVdZiR0"},"source":[""],"execution_count":null,"outputs":[]}]}