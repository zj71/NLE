{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Lab_10_1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"j90VrhDVK-wu"},"source":["# Week 10: Information Retrieval and Question Answering\n","\n","This week we are looking at the tasks of information retrieval and question answering.  In the lab we will look at:\n","* finding relevant documents to a query expressed in terms of keywords\n","* extracting keywords from a query"]},{"cell_type":"code","metadata":{"id":"pMhebx_BLFKd"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BqZxoUMWK-wv"},"source":["#preliminary imports\n","import pandas as pd\n","from itertools import zip_longest\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","import re\n","import math\n","import operator\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d_7sHf2xK-ww"},"source":["We will be using the Stanford Question Answering Dataset (SQUAD) dataset in this lab, provided in the resources for this week.  For more information about the dataset and the ongoing competition, see the website:  https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n","\n","The dataset is provided as 2 json files - one for development and one for training.  Lets read in the smaller development dataset using the json library."]},{"cell_type":"code","metadata":{"id":"GrELELYXK-ww"},"source":["import json\n","filename=\"/content/drive/My Drive/NLE Notebooks/Week10Labs/Squad/dev-v2.0.json\"\n","\n","with open(filename,'r') as inputstream:\n","    devdata=json.load(inputstream)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SHjXUI3jK-ww"},"source":["The data is now stored in devdata as a deeply-nested dictionary structure.  The `data` field contains a list of dictionaries - one for each of the documents in the dataset."]},{"cell_type":"code","metadata":{"id":"QDXUhuSyK-ww"},"source":["len(devdata['data'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8l5BxR0sK-wx"},"source":["Each document dictionary has two key-value pairs."]},{"cell_type":"code","metadata":{"id":"ToekUYHRK-wy"},"source":["len(devdata['data'][0].keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDueIs74K-wy"},"source":["list(devdata['data'][0].keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lZGrOwOK-wy"},"source":["The `paragraphs` field of a document dictionary is a further list of paragraphs!"]},{"cell_type":"code","metadata":{"id":"UaRRuaylK-wy"},"source":["len(devdata['data'][0]['paragraphs'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVS1Wa-FK-wy"},"source":["Each paragraph is a dictionary.  One field `context` contains the text of the paragraph as a String.  "]},{"cell_type":"code","metadata":{"id":"gVkd5iGzK-wy"},"source":["list(devdata['data'][0]['paragraphs'][0].keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOpTu63PK-wy"},"source":["devdata['data'][0]['paragraphs'][0]['context']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmNt4huvK-wz"},"source":["The other field `qas` is a list of dictionaries.  Each dictionary contains a `question`, a list of possible `answers`, a unique `id` and a value for `is_impossible` which indicates whether the question is answerable or not given the `context`"]},{"cell_type":"code","metadata":{"id":"MKtlcu8oK-wz"},"source":["devdata['data'][0]['paragraphs'][0]['qas']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9RJLVbhK-wz"},"source":["To make it easier to work with, lets turn this data structure into 2 simple lists containing the bits that we want.  The first will contain the `context` from the paragraphs and the other will contain the corresponding lists of questions and answers or `qas`."]},{"cell_type":"code","metadata":{"id":"duDYnPG1K-wz"},"source":["def get_text_qas(dataset):\n","    textlist=[]\n","    qalist=[]\n","    for document in dataset['data']:\n","        for para in document['paragraphs']:\n","            textlist.append(para['context'])\n","            qalist.append(para['qas'])\n","    \n","    \n","    return textlist,qalist\n","    \n","    \n","textlist,qalist=get_text_qas(devdata)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ts1fnUhBK-wz"},"source":["print(textlist[1:2])\n","print(qalist[1:2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZ-tARcQK-wz"},"source":["## Keyword Search\n","In order to perform a keyword search of a document collection, the collection needs to be indexed by words.  The index is a mapping from keywords to lists of document ids containing that document.\n","\n","Here, we will consider each paragraph as an individual document and its **id** is its position in the `textlist` list created above\n","\n","### Exercise 1.1\n","Write a function `extract_keywords()` which takes a string and returns a set of keywords.  Make sure you carry out appropriate normalisation and filtering"]},{"cell_type":"code","metadata":{"id":"HHaPtUfFK-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5QBVBbcK-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbt_8q6VK-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nxk5agRYK-wz"},"source":["### Exercise 1.2\n","Create a keyword index for the paragraphs in textlist.  "]},{"cell_type":"code","metadata":{"id":"LhMnAMJDK-wz"},"source":["\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBFVRYneK-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hdsVDORvK-wz"},"source":["### Exercise 1.3\n","Write a class `docssearch` that is initialised with a list of strings, stores the list of strings and also creates an index.  Then write a method to search the keyword index for a single keyword and returns a list of paragraphs containing that keyword.  \n","\n"]},{"cell_type":"code","metadata":{"id":"thl6sdi6K-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2VZNyasK-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XndIbTmnK-wz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z_XEYlOSK-wz"},"source":["The `merge` function below can be used to efficiently intersect two sorted lists.  It is based on the *merge* of *mergesort*.   You might want to test it out on some other lists.  Remember it will only work if the inputs are sorted."]},{"cell_type":"code","metadata":{"id":"RTHNdQS2K-w0"},"source":["def merge(list1,list2):\n","    '''\n","    function to intersect 2 sorted lists\n","    '''\n","    pointer1=0\n","    pointer2=0\n","    merged=[]\n","    while pointer1<len(list1) and pointer2<len(list2):\n","        if list1[pointer1]==list2[pointer2]:\n","            merged.append(list1[pointer1])\n","            pointer1+=1\n","            pointer2+=1\n","            \n","        elif list1[pointer1]<list2[pointer2]:\n","            pointer1+=1\n","        else:\n","            pointer2+=1\n","            \n","    return merged\n","\n","merge([1,5,7,8],[3,6,7,8,15])\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81vpj1KyK-w0"},"source":["### Exercise 1.4\n","Add a method `listsearch` that takes a list of keywords and returns a list of paragraphs which contains all of them.\n","\n","Make sure your list of keywords is normalised and filtered in the same way as your paragraph text."]},{"cell_type":"code","metadata":{"id":"RAhcm7mOK-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YU1b7SybK-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XgcDWyLmK-w0"},"source":["A search for paragraphs relevant to the keywords 'political' and 'kingdom' should return 2 paragraphs.  The first starts 'The Norman dynasty ...' and the second starts 'Throughout the 1980s and 1990s ...'"]},{"cell_type":"code","metadata":{"id":"4QG2AAwaK-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YHcdPoKMK-w0"},"source":["## Ranking Documents\n","A rank for a document can be calculated using the **sum** or the **product** of the tf-idf scores of each word in the query calculated over the documents\n","\n","* Why weight the words by tf-idf?\n","* What difference does using the sum or the product make intuitively?\n","\n","Alternatively, you can calculate the cosine similarity of the query to each document.\n","\n","* What information does using cosine incorporate that is ignored by the simple sum or product measures?\n","\n","\n","### Exercise 2.1\n","Generate tf-idf representations of each of the paragraphs (look back to earlier labs to review how to do this).  Store these representations in the `docsearch` class as well.  Then use one of the ranking schemes described above to rank the documents returned by your `listsearch` method.\n","\n","Using a product of tf-idf scores, you should find that the first ranked document for the search \\['political','conquered'\\] is para 1031 with a score of 114; whereas using a sum it is para 1031 with a score of 27.7"]},{"cell_type":"code","metadata":{"id":"XnZYmb96K-w0"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvuTq9Z_K-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZltFoK_mK-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32GLRoh9K-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-FLixxj8K-w0"},"source":["## Extensions\n","\n","Implement one or more of the following extensions.\n","\n","### Extension 1\n","\n","In order to be able to answer natural language queries, it is also necessary to extract keywords from questions.\n","\n","You can use the `input()` function to take in a query from keyboard.  Use this together with the functionality you have already developed to make a prototype of a system which returns the most relevant paragraph to a given query. "]},{"cell_type":"code","metadata":{"id":"3KGP0BKnK-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7ucex1QK-w0"},"source":["### Extension 2\n","\n","Find the sentences within a paragraph which are most relevant to a query.\n"]},{"cell_type":"code","metadata":{"id":"CYdhvRwwK-w0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"njm-QNsZK-w0"},"source":["### Extension 3\n","\n","Build a classifier to determine whether a given query is answerable on the basis of a given relevant paragraph. \n","\n","You will need to use the `qalist` which has positive and negative examples of answerable questions for each paragraph.\n","\n","An instance is then a paragraph and an answer pair which has been labelled answerable or unanswerable.  You can extract features from both the paragraph and the answer (e.g., bags-of-words) and then make a representation of the instance by applying some operation to the two vectors e.g., addition, subtraction, multiplication or concatenation."]},{"cell_type":"code","metadata":{"id":"Xs6ROM6hK-w0"},"source":[""],"execution_count":null,"outputs":[]}]}